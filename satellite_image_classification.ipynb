{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2546969,
          "sourceType": "datasetVersion",
          "datasetId": 1544742
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install necessary packages"
      ],
      "metadata": {
        "id": "aiL5ryEGryF7",
        "outputId": "e40e9c65-db2b-428f-e535-116417cfed13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsampler\n",
        "!pip install torchmetrics\n",
        "!pip install split-folders"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:41:39.657518Z",
          "iopub.execute_input": "2024-04-10T06:41:39.658238Z",
          "iopub.status.idle": "2024-04-10T06:42:17.641316Z",
          "shell.execute_reply.started": "2024-04-10T06:41:39.658207Z",
          "shell.execute_reply": "2024-04-10T06:42:17.640243Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdMIT3fF2GoK",
        "outputId": "03a2b877-57ca-491c-b8e3-cecb62b356c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsampler\n",
            "  Downloading torchsampler-0.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (0.20.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsampler) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3->torchsampler) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->torchsampler) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->torchsampler) (3.0.2)\n",
            "Downloading torchsampler-0.1.2-py3-none-any.whl (5.6 kB)\n",
            "Installing collected packages: torchsampler\n",
            "Successfully installed torchsampler-0.1.2\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.1\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  2. Import required libraries"
      ],
      "metadata": {
        "id": "vnN5WLYW2GoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm.autonotebook import tqdm, trange\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix, classification_report\n",
        "from torchsampler import ImbalancedDatasetSampler\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, LeakyReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout"
      ],
      "metadata": {
        "id": "GEPF5Hprr1k1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "5b1095da-32d6-465f-8e1e-5ee8e2209460",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:43:48.197802Z",
          "iopub.execute_input": "2024-04-10T06:43:48.198473Z",
          "iopub.status.idle": "2024-04-10T06:43:56.104002Z",
          "shell.execute_reply.started": "2024-04-10T06:43:48.198439Z",
          "shell.execute_reply": "2024-04-10T06:43:56.103174Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-3c150808795e>:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchsampler'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3c150808795e>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsampler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImbalancedDatasetSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsampler'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Pre-processing"
      ],
      "metadata": {
        "id": "to0LoSj62GoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "\n",
        "# Split the dataset into train, test, and val folders\n",
        "splitfolders.ratio('/kaggle/input/satellite_image_classification/data', output=\"data1\", seed=1337, ratio=(.7, 0.2, 0.1))\n",
        "\n",
        "# Define the paths to train, test, and val folders\n",
        "train_folder = \"data1/train\"\n",
        "test_folder = \"data1/test\"\n",
        "val_folder = \"data1/val\"\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:43:58.451893Z",
          "iopub.execute_input": "2024-04-10T06:43:58.452421Z",
          "iopub.status.idle": "2024-04-10T06:44:23.334918Z",
          "shell.execute_reply.started": "2024-04-10T06:43:58.452390Z",
          "shell.execute_reply": "2024-04-10T06:44:23.334062Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "aPyKTCiJ2GoM",
        "outputId": "7c258e6b-faaa-406e-b9fa-c6868fa820b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'splitfolders'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e7f2487f6b42>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Split the dataset into train, test, and val folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/satellite_image_classification/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'splitfolders'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation**"
      ],
      "metadata": {
        "id": "sk6V0zjt2GoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.Resize((256,256)),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomRotation(90),\n",
        "                                       transforms.ToTensor(),\n",
        "\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "                                       transforms.Resize((256,256)),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomRotation(90),\n",
        "                                       transforms.ToTensor(),\n",
        "\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                                       transforms.Resize((256,256)),\n",
        "                                       transforms.ToTensor(),\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "p5FduGFbUH64",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:48:18.189163Z",
          "iopub.execute_input": "2024-04-10T06:48:18.189970Z",
          "iopub.status.idle": "2024-04-10T06:48:18.196981Z",
          "shell.execute_reply.started": "2024-04-10T06:48:18.189936Z",
          "shell.execute_reply": "2024-04-10T06:48:18.195881Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Create data loaders**"
      ],
      "metadata": {
        "id": "FEzNUtCP2GoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root = train_folder, transform=train_transforms)\n",
        "val_dataset = torchvision.datasets.ImageFolder(root = val_folder, transform=val_transforms)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root = test_folder, transform=test_transforms)"
      ],
      "metadata": {
        "id": "CcP3xZGQUK69",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:48:20.067148Z",
          "iopub.execute_input": "2024-04-10T06:48:20.067787Z",
          "iopub.status.idle": "2024-04-10T06:48:20.100237Z",
          "shell.execute_reply.started": "2024-04-10T06:48:20.067757Z",
          "shell.execute_reply": "2024-04-10T06:48:20.099371Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=32)\n",
        "val_loader = torch.utils.data.DataLoader(dataset = val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "ncQxo4bFUQVq",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:48:21.817747Z",
          "iopub.execute_input": "2024-04-10T06:48:21.818138Z",
          "iopub.status.idle": "2024-04-10T06:48:21.862372Z",
          "shell.execute_reply.started": "2024-04-10T06:48:21.818108Z",
          "shell.execute_reply": "2024-04-10T06:48:21.861344Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "FgoSUGEzUUKF",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:48:23.414009Z",
          "iopub.execute_input": "2024-04-10T06:48:23.414407Z",
          "iopub.status.idle": "2024-04-10T06:48:23.473935Z",
          "shell.execute_reply.started": "2024-04-10T06:48:23.414378Z",
          "shell.execute_reply": "2024-04-10T06:48:23.472826Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Model definition**"
      ],
      "metadata": {
        "id": "xDkGjA4z2GoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.alexnet(pretrained=True)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "WoTS8vMjUXew",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:49:21.063531Z",
          "iopub.execute_input": "2024-04-10T06:49:21.063927Z",
          "iopub.status.idle": "2024-04-10T06:49:23.488624Z",
          "shell.execute_reply.started": "2024-04-10T06:49:21.063897Z",
          "shell.execute_reply": "2024-04-10T06:49:23.487701Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Modifying the Classifier**"
      ],
      "metadata": {
        "id": "FKG_If6E2GoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] =  nn.Linear(num_ftrs, 4)"
      ],
      "metadata": {
        "id": "jQwtecEgVIAd",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:50:34.617633Z",
          "iopub.execute_input": "2024-04-10T06:50:34.617992Z",
          "iopub.status.idle": "2024-04-10T06:50:34.624234Z",
          "shell.execute_reply.started": "2024-04-10T06:50:34.617966Z",
          "shell.execute_reply": "2024-04-10T06:50:34.623212Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Loss function and optimizer**"
      ],
      "metadata": {
        "id": "tZfSZnn22GoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available() == True:\n",
        "    model = model.cuda()\n",
        "else:\n",
        "    model = model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = GradScaler(enabled=True)\n",
        "use_cuda = True"
      ],
      "metadata": {
        "id": "52qYFHQlVNoM",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:53:33.826746Z",
          "iopub.execute_input": "2024-04-10T06:53:33.827793Z",
          "iopub.status.idle": "2024-04-10T06:53:33.835796Z",
          "shell.execute_reply.started": "2024-04-10T06:53:33.827751Z",
          "shell.execute_reply": "2024-04-10T06:53:33.834772Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Training and testing functions**"
      ],
      "metadata": {
        "id": "8ZCFfKF82GoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accu = []\n",
        "training_loss = []\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    image_preds_all = []\n",
        "    image_targets_all = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
        "\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "\n",
        "        with autocast():\n",
        "\n",
        "            y_pred = model(x)\n",
        "\n",
        "            image_preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n",
        "            image_targets_all += [y.detach().cpu().numpy()]\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    image_preds_all = np.concatenate(image_preds_all)\n",
        "    image_targets_all = np.concatenate(image_targets_all)\n",
        "    score = (image_preds_all==image_targets_all).mean()\n",
        "\n",
        "    train_losss = epoch_loss / len(iterator)\n",
        "\n",
        "    train_accu.append(score*100)\n",
        "    training_loss.append(train_losss)\n",
        "\n",
        "    #print(score)\n",
        "    #print(len(train_accu), len(training_loss))\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), train_accu, training_loss"
      ],
      "metadata": {
        "id": "fFHAPeLoVWEh",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:53:38.491803Z",
          "iopub.execute_input": "2024-04-10T06:53:38.492142Z",
          "iopub.status.idle": "2024-04-10T06:53:38.502226Z",
          "shell.execute_reply.started": "2024-04-10T06:53:38.492119Z",
          "shell.execute_reply": "2024-04-10T06:53:38.501286Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_accu = []\n",
        "eval_loss = []\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    image_preds_all = []\n",
        "    image_targets_all = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
        "\n",
        "            x = x.to(device).float()\n",
        "            y = y.to(device).long()\n",
        "\n",
        "            y_pred = model(x)\n",
        "\n",
        "            image_preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n",
        "            image_targets_all += [y.detach().cpu().numpy()]\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    image_preds_all = np.concatenate(image_preds_all)\n",
        "    image_targets_all = np.concatenate(image_targets_all)\n",
        "    score = (image_preds_all==image_targets_all).mean()\n",
        "\n",
        "    val_losss = epoch_loss / len(iterator)\n",
        "\n",
        "    val_accu.append(score*100)\n",
        "    eval_loss.append(val_losss)\n",
        "\n",
        "    performance_matrix(image_targets_all, image_preds_all)\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), val_accu, eval_loss"
      ],
      "metadata": {
        "id": "l9bxrvlEVY0Z",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:53:41.168491Z",
          "iopub.execute_input": "2024-04-10T06:53:41.168858Z",
          "iopub.status.idle": "2024-04-10T06:53:41.178872Z",
          "shell.execute_reply.started": "2024-04-10T06:53:41.168830Z",
          "shell.execute_reply": "2024-04-10T06:53:41.177690Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_matrix(true,pred):\n",
        "    precision = precision_score(true,pred,average='macro')\n",
        "    recall = recall_score(true,pred,average='macro')\n",
        "    accuracy = accuracy_score(true,pred)\n",
        "    f1_sco = f1_score(true,pred,average='macro')\n",
        "    print('Precision: {:.4f} Recall: {:.4f}, Accuracy: {:.4f}: ,f1_score: {:.4f}'.format(precision,recall,accuracy,f1_sco))\n",
        "    print('Classification Report:\\n',classification_report(true, pred))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:53:57.195201Z",
          "iopub.execute_input": "2024-04-10T06:53:57.195584Z",
          "iopub.status.idle": "2024-04-10T06:53:57.201819Z",
          "shell.execute_reply.started": "2024-04-10T06:53:57.195559Z",
          "shell.execute_reply": "2024-04-10T06:53:57.200646Z"
        },
        "trusted": true,
        "id": "QTgu-yll2GoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:54:07.570032Z",
          "iopub.execute_input": "2024-04-10T06:54:07.570399Z",
          "iopub.status.idle": "2024-04-10T06:54:07.575979Z",
          "shell.execute_reply.started": "2024-04-10T06:54:07.570372Z",
          "shell.execute_reply": "2024-04-10T06:54:07.574669Z"
        },
        "trusted": true,
        "id": "30FyLWx-2GoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "dEOVgoaXVc7c",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:54:23.133497Z",
          "iopub.execute_input": "2024-04-10T06:54:23.133898Z",
          "iopub.status.idle": "2024-04-10T06:54:23.139415Z",
          "shell.execute_reply.started": "2024-04-10T06:54:23.133862Z",
          "shell.execute_reply": "2024-04-10T06:54:23.138225Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint_model(epoch, model, opt, best_val_acc, model_path):\n",
        "    model_state_dict = model.state_dict() if (device.type == 'cuda') else model.state_dict()\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model_state_dict,\n",
        "        'opt_state_dict': opt.state_dict(),\n",
        "        'best_val_acc': best_val_acc\n",
        "    }, model_path)"
      ],
      "metadata": {
        "id": "XtuWwUiTVfzP",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:54:41.259289Z",
          "iopub.execute_input": "2024-04-10T06:54:41.259962Z",
          "iopub.status.idle": "2024-04-10T06:54:41.265370Z",
          "shell.execute_reply.started": "2024-04-10T06:54:41.259928Z",
          "shell.execute_reply": "2024-04-10T06:54:41.264291Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['opt_state_dict'])\n",
        "    return model, optimizer, checkpoint['epoch']"
      ],
      "metadata": {
        "id": "Y-_eiY2rVlNW",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:54:43.324256Z",
          "iopub.execute_input": "2024-04-10T06:54:43.324652Z",
          "iopub.status.idle": "2024-04-10T06:54:43.329983Z",
          "shell.execute_reply.started": "2024-04-10T06:54:43.324624Z",
          "shell.execute_reply": "2024-04-10T06:54:43.329020Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Training and validating the model**"
      ],
      "metadata": {
        "id": "Wu8AXYib2GoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "best_val_acc = 0.\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "train_acc_gr = []\n",
        "train_loss_gr = []\n",
        "val_acc_gr = []\n",
        "val_loss_gr = []\n",
        "\n",
        "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    train_loss, train_acc, train_acc_gr, train_loss_gr = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc, val_acc_gr, val_loss_gr = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    if epoch % 30 == 0:\n",
        "        checkpoint_model(epoch, model, optimizer, best_val_acc, '/kaggle/working/CNN_epoch%d.pth' % epoch)\n",
        "\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "\n",
        "plt.plot(train_acc_gr,'-o')\n",
        "plt.plot(val_acc_gr,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.title('Train vs Valid Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_loss_gr,'-o')\n",
        "plt.plot(val_loss_gr,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.title('Train vs Valid Losses')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XczC7kpKVm-a",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:55:50.913182Z",
          "iopub.execute_input": "2024-04-10T06:55:50.913600Z",
          "iopub.status.idle": "2024-04-10T06:57:06.196239Z",
          "shell.execute_reply.started": "2024-04-10T06:55:50.913570Z",
          "shell.execute_reply": "2024-04-10T06:57:06.194561Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Testing the model**"
      ],
      "metadata": {
        "id": "Tdhk9UZD2GoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "image_preds_all = []\n",
        "image_targets_all = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for (x, y) in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
        "\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "\n",
        "        y_pred = model(x)\n",
        "\n",
        "        image_preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n",
        "        image_targets_all += [y.detach().cpu().numpy()]\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "image_preds_all = np.concatenate(image_preds_all)\n",
        "image_targets_all = np.concatenate(image_targets_all)\n",
        "score = (image_preds_all==image_targets_all).mean()\n",
        "\n",
        "performance_matrix(image_targets_all, image_preds_all)"
      ],
      "metadata": {
        "id": "8nCiFEl4WzvE",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:01:06.386091Z",
          "iopub.execute_input": "2024-04-10T06:01:06.386629Z",
          "iopub.status.idle": "2024-04-10T06:01:09.238561Z",
          "shell.execute_reply.started": "2024-04-10T06:01:06.386590Z",
          "shell.execute_reply": "2024-04-10T06:01:09.237707Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path, model, transform, device):\n",
        "    # Load the image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # Apply the same transformations as used during training\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Move the image to the device (GPU/CPU)\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Make prediction without calculating gradients\n",
        "    with torch.no_grad():\n",
        "        # Get the model's output\n",
        "        output = model(image)\n",
        "\n",
        "        # Get the predicted class\n",
        "        _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "    # Return the predicted class\n",
        "    return predicted_class.item()\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/kaggle/input/satellite-image-classification/data/cloudy/train_10043.jpg'  # Replace with the path to the image you want to predict\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "predicted_class = predict_image(image_path, model, transform, device)\n",
        "if predicted_class==0:\n",
        "    print(f'The predicted class for the given image is: cloudy')\n",
        "elif predicted_class==1:\n",
        "    print(f'The predicted class for the given image is: desert')\n",
        "elif predicted_class==2:\n",
        "    print(f'The predicted class for the given image is: green area')\n",
        "elif predicted_class==3:\n",
        "    print(f'The predicted class for the given image is: water')\n"
      ],
      "metadata": {
        "id": "T-FO2ALNK61v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}